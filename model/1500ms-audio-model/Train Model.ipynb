{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ZuigSoBOgNw"
   },
   "source": [
    "# Training\n",
    "\n",
    "This treats the spectrograms of the words like images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2399,
     "status": "ok",
     "timestamp": 1599330912465,
     "user": {
      "displayName": "Chris Greening",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhzkETr7y27ciZfW4lregDo2YPFRrA30ouOuL6TIQ=s64",
      "userId": "14199137355227635747"
     },
     "user_tz": -60
    },
    "id": "aa6niXGfOgNx"
   },
   "outputs": [],
   "source": [
    "# Import all the things we will need\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.data import Dataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25328,
     "status": "ok",
     "timestamp": 1599324137392,
     "user": {
      "displayName": "Chris Greening",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhzkETr7y27ciZfW4lregDo2YPFRrA30ouOuL6TIQ=s64",
      "userId": "14199137355227635747"
     },
     "user_tz": -60
    },
    "id": "QKSFOZvEOgN3"
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension - if you want it inline - this can be a bit flaky...\n",
    "# %load_ext tensorboard\n",
    "# %reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25328,
     "status": "ok",
     "timestamp": 1599324137392,
     "user": {
      "displayName": "Chris Greening",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhzkETr7y27ciZfW4lregDo2YPFRrA30ouOuL6TIQ=s64",
      "userId": "14199137355227635747"
     },
     "user_tz": -60
    },
    "id": "QKSFOZvEOgN3"
   },
   "outputs": [],
   "source": [
    "# clear out any old logs\n",
    "!rm -rf ./logs/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24601,
     "status": "ok",
     "timestamp": 1599324137393,
     "user": {
      "displayName": "Chris Greening",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhzkETr7y27ciZfW4lregDo2YPFRrA30ouOuL6TIQ=s64",
      "userId": "14199137355227635747"
     },
     "user_tz": -60
    },
    "id": "-EENm2XtOgN6"
   },
   "outputs": [],
   "source": [
    "# List of the words in categorical order\n",
    "words = [\n",
    "    'backward',\n",
    "    'bed',\n",
    "    'bird',\n",
    "    'cat',\n",
    "    'dog',\n",
    "    'down',\n",
    "    'eight',\n",
    "    'five',\n",
    "    'follow',\n",
    "    'forward',\n",
    "    'four',\n",
    "    'go',\n",
    "    'happy',\n",
    "    'house',\n",
    "    'learn',\n",
    "    'left',\n",
    "    'marvin',\n",
    "    'nine',\n",
    "    'no',\n",
    "    'off',\n",
    "    'on',\n",
    "    'one',\n",
    "    'right',\n",
    "    'seven',\n",
    "    'sheila',\n",
    "    'six',\n",
    "    'stop',\n",
    "    'three',\n",
    "    'tree',\n",
    "    'two',\n",
    "    'up',\n",
    "    'visual',\n",
    "    'wow',\n",
    "    'yes',\n",
    "    'zero',\n",
    "    '_background',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5271,
     "status": "ok",
     "timestamp": 1599324142683,
     "user": {
      "displayName": "Chris Greening",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhzkETr7y27ciZfW4lregDo2YPFRrA30ouOuL6TIQ=s64",
      "userId": "14199137355227635747"
     },
     "user_tz": -60
    },
    "id": "ERCnsdwMOgN9"
   },
   "outputs": [],
   "source": [
    "# Load up the sprectrograms and labels\n",
    "training_spectrogram = np.load('training_spectrogram.npz')\n",
    "validation_spectrogram = np.load('validation_spectrogram.npz')\n",
    "test_spectrogram = np.load('test_spectrogram.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 30633,
     "status": "ok",
     "timestamp": 1599324168055,
     "user": {
      "displayName": "Chris Greening",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhzkETr7y27ciZfW4lregDo2YPFRrA30ouOuL6TIQ=s64",
      "userId": "14199137355227635747"
     },
     "user_tz": -60
    },
    "id": "4L_A47mDOgN_"
   },
   "outputs": [],
   "source": [
    "# extract the data from the files\n",
    "X_train = training_spectrogram['X']\n",
    "Y_train_cats = training_spectrogram['Y']\n",
    "X_validate = validation_spectrogram['X']\n",
    "Y_validate_cats = validation_spectrogram['Y']\n",
    "X_test = test_spectrogram['X']\n",
    "Y_test_cats = test_spectrogram['Y']\n",
    "\n",
    "# get the width and height of the spectrogram \"image\"\n",
    "IMG_WIDTH=X_train[0].shape[0]\n",
    "IMG_HEIGHT=X_train[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 518
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 30626,
     "status": "ok",
     "timestamp": 1599324168057,
     "user": {
      "displayName": "Chris Greening",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhzkETr7y27ciZfW4lregDo2YPFRrA30ouOuL6TIQ=s64",
      "userId": "14199137355227635747"
     },
     "user_tz": -60
    },
    "id": "IquLGwB6pSwR",
    "outputId": "653df24c-9a30-4e01-9aa1-b1f213aecf8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  991.,   470.,   697.,   536.,   760.,  1466.,   959.,   944.,\n",
       "          460.,   681.,   897.,   805.,   671.,   823.,   648.,  1302.,\n",
       "        88060.,  1942.,  1172.,   593.,  1118.,  1088.,  1117.,  1728.,\n",
       "         1262.,  1911.,  1032.,  1037.,   734.,   921.,   414.,   944.,\n",
       "          841.,  1611.,  2405.,  5424.]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "        34, 35, 36]),\n",
       " <BarContainer object of 36 artists>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot a distribution of the words\n",
    "plt.hist(Y_train_cats, bins=range(0,len(words)+1), align='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27938,
     "status": "ok",
     "timestamp": 1599324168058,
     "user": {
      "displayName": "Chris Greening",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhzkETr7y27ciZfW4lregDo2YPFRrA30ouOuL6TIQ=s64",
      "userId": "14199137355227635747"
     },
     "user_tz": -60
    },
    "id": "ZXHaeU4uqLnM",
    "outputId": "48fb554d-8f2b-450d-db45-233bf350b197"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35] [  991   470   697   536   760  1466   959   944   460   681   897   805\n",
      "   671   823   648  1302 88060  1942  1172   593  1118  1088  1117  1728\n",
      "  1262  1911  1032  1037   734   921   414   944   841  1611  2405  5424]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'backward': 991,\n",
       " 'bed': 470,\n",
       " 'bird': 697,\n",
       " 'cat': 536,\n",
       " 'dog': 760,\n",
       " 'down': 1466,\n",
       " 'eight': 959,\n",
       " 'five': 944,\n",
       " 'follow': 460,\n",
       " 'forward': 681,\n",
       " 'four': 897,\n",
       " 'go': 805,\n",
       " 'happy': 671,\n",
       " 'house': 823,\n",
       " 'learn': 648,\n",
       " 'left': 1302,\n",
       " 'marvin': 88060,\n",
       " 'nine': 1942,\n",
       " 'no': 1172,\n",
       " 'off': 593,\n",
       " 'on': 1118,\n",
       " 'one': 1088,\n",
       " 'right': 1117,\n",
       " 'seven': 1728,\n",
       " 'sheila': 1262,\n",
       " 'six': 1911,\n",
       " 'stop': 1032,\n",
       " 'three': 1037,\n",
       " 'tree': 734,\n",
       " 'two': 921,\n",
       " 'up': 414,\n",
       " 'visual': 944,\n",
       " 'wow': 841,\n",
       " 'yes': 1611,\n",
       " 'zero': 2405,\n",
       " '_background': 5424}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(Y_train_cats, return_counts=True)\n",
    "print(unique, counts)\n",
    "dict(zip([words[i] for i in unique], counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "ok",
     "timestamp": 1599324169547,
     "user": {
      "displayName": "Chris Greening",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhzkETr7y27ciZfW4lregDo2YPFRrA30ouOuL6TIQ=s64",
      "userId": "14199137355227635747"
     },
     "user_tz": -60
    },
    "id": "946JWm6Fe2Wd"
   },
   "outputs": [],
   "source": [
    "Y_train = [1 if y == words.index('marvin') else 0 for y in Y_train_cats]\n",
    "Y_validate = [1 if y == words.index('marvin') else 0 for y in Y_validate_cats]\n",
    "Y_test = [1 if y == words.index('marvin') else 0 for y in Y_test_cats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "ok",
     "timestamp": 1599324169547,
     "user": {
      "displayName": "Chris Greening",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhzkETr7y27ciZfW4lregDo2YPFRrA30ouOuL6TIQ=s64",
      "userId": "14199137355227635747"
     },
     "user_tz": -60
    },
    "id": "946JWm6Fe2Wd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([40404., 88060.]), array([0, 1, 2]), <BarContainer object of 2 artists>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAARq0lEQVR4nO3df5BdZX3H8feniQF/FAiSIibUhDGtE5gqmEH8MVbBgYAdQ6dqQ7VES6UKWK2dqaHMFAdlKm2nKKPiMBAB6wiY2pIKlEbA6XRsAosgEBBZgkpSfkTCj1JHNPjtH/eJHsJu9i67ezch79fMnT3neZ5z7vc+Z8nn3nPOXlJVSJJ2b7823QVIkqafYSBJMgwkSYaBJAnDQJIEzJzuAp6r/fbbr+bPnz/dZUjSLuPmm2/+cVXNGalvlw2D+fPnMzQ0NN1lSNIuI8kPR+vzNJEkyTCQJBkGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIktiF/wJZ2lnNX3HVdJeg57EffPrtU7JfPxlIkgwDSZJhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJPoMgyR/kWR9kjuSfDXJnkkWJFmXZDjJ5UlmtbF7tPXh1j+/s5/TW/vdSY7ptC9pbcNJVkz6q5Qk7dCYYZBkLvDnwOKqOgSYASwDzgHOrapXAo8CJ7VNTgIebe3ntnEkWdS2OxhYAnwhyYwkM4DPA8cCi4AT2lhJ0oD0e5poJvDCJDOBFwEPAEcCq1r/JcDxbXlpW6f1H5Ukrf2yqnqqqu4DhoHD22O4qjZU1c+Ay9pYSdKAjBkGVbUJ+AfgR/RC4HHgZuCxqtrahm0E5rblucD9bdutbfxLu+3bbTNa+7MkOTnJUJKhzZs39/P6JEl96Oc00Wx679QXAC8HXkzvNM/AVdUFVbW4qhbPmTNnOkqQpOelfk4TvQ24r6o2V9XPga8DbwT2aaeNAOYBm9ryJuBAgNa/N/BIt327bUZrlyQNSD9h8CPgiCQvauf+jwLuBG4A3tnGLAeubMur2zqt//qqqta+rN1ttABYCNwI3AQsbHcnzaJ3kXn1xF+aJKlfM8caUFXrkqwCvgNsBW4BLgCuAi5L8qnWdlHb5CLgy0mGgS30/nGnqtYnuYJekGwFTq2qpwGSnAZcS+9OpZVVtX7yXqIkaSxjhgFAVZ0JnLld8wZ6dwJtP/anwLtG2c/ZwNkjtF8NXN1PLZKkyedfIEuSDANJkmEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEn0GQZJ9kmyKsn3ktyV5PVJ9k2yJsk97efsNjZJzksynOS2JId19rO8jb8nyfJO+2uT3N62OS9JJv+lSpJG0+8ng88C/15VrwJeDdwFrACuq6qFwHVtHeBYYGF7nAycD5BkX+BM4HXA4cCZ2wKkjflAZ7slE3tZkqTxGDMMkuwNvBm4CKCqflZVjwFLgUvasEuA49vyUuDS6lkL7JPkAOAYYE1VbamqR4E1wJLWt1dVra2qAi7t7EuSNAD9fDJYAGwGvpTkliQXJnkxsH9VPdDGPAjs35bnAvd3tt/Y2nbUvnGE9mdJcnKSoSRDmzdv7qN0SVI/+gmDmcBhwPlVdSjwf/zqlBAA7R19TX55z1RVF1TV4qpaPGfOnKl+OknabfQTBhuBjVW1rq2vohcOD7VTPLSfD7f+TcCBne3ntbYdtc8boV2SNCBjhkFVPQjcn+S3W9NRwJ3AamDbHUHLgSvb8mrgxHZX0RHA4+100rXA0UlmtwvHRwPXtr4nkhzR7iI6sbMvSdIAzOxz3IeBrySZBWwA3k8vSK5IchLwQ+DdbezVwHHAMPCTNpaq2pLkk8BNbdxZVbWlLZ8CXAy8ELimPSRJA9JXGFTVrcDiEbqOGmFsAaeOsp+VwMoR2oeAQ/qpRZI0+fwLZEmSYSBJMgwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJIlxhEGSGUluSfKNtr4gybokw0kuTzKrte/R1odb//zOPk5v7XcnOabTvqS1DSdZMYmvT5LUh/F8MvgIcFdn/Rzg3Kp6JfAocFJrPwl4tLWf28aRZBGwDDgYWAJ8oQXMDODzwLHAIuCENlaSNCAz+xmUZB7wduBs4GNJAhwJ/FEbcgnwCeB8YGlbBlgFfK6NXwpcVlVPAfclGQYOb+OGq2pDe67L2tg7J/TKdmD+iqumateStEvq95PBZ4C/An7R1l8KPFZVW9v6RmBuW54L3A/Q+h9v43/Zvt02o7U/S5KTkwwlGdq8eXOfpUuSxjJmGCT5PeDhqrp5APXsUFVdUFWLq2rxnDlzprscSXre6Oc00RuBdyQ5DtgT2Av4LLBPkpnt3f88YFMbvwk4ENiYZCawN/BIp32b7jajtUuSBmDMTwZVdXpVzauq+fQuAF9fVe8BbgDe2YYtB65sy6vbOq3/+qqq1r6s3W20AFgI3AjcBCxsdyfNas+xelJenSSpL31dQB7Fx4HLknwKuAW4qLVfBHy5XSDeQu8fd6pqfZIr6F0Y3gqcWlVPAyQ5DbgWmAGsrKr1E6hLkjRO4wqDqvoW8K22vIFf3Q3UHfNT4F2jbH82vTuStm+/Grh6PLVIkiaPf4EsSTIMJEmGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAk0UcYJDkwyQ1J7kyyPslHWvu+SdYkuaf9nN3ak+S8JMNJbktyWGdfy9v4e5Is77S/NsntbZvzkmQqXqwkaWT9fDLYCvxlVS0CjgBOTbIIWAFcV1ULgevaOsCxwML2OBk4H3rhAZwJvA44HDhzW4C0MR/obLdk4i9NktSvMcOgqh6oqu+05f8F7gLmAkuBS9qwS4Dj2/JS4NLqWQvsk+QA4BhgTVVtqapHgTXAkta3V1WtraoCLu3sS5I0AOO6ZpBkPnAosA7Yv6oeaF0PAvu35bnA/Z3NNra2HbVvHKF9pOc/OclQkqHNmzePp3RJ0g70HQZJXgL8M/DRqnqi29fe0dck1/YsVXVBVS2uqsVz5syZ6qeTpN1GX2GQ5AX0guArVfX11vxQO8VD+/lwa98EHNjZfF5r21H7vBHaJUkD0s/dRAEuAu6qqn/sdK0Gtt0RtBy4stN+Yrur6Ajg8XY66Vrg6CSz24Xjo4FrW98TSY5oz3ViZ1+SpAGY2ceYNwJ/DNye5NbW9tfAp4ErkpwE/BB4d+u7GjgOGAZ+ArwfoKq2JPkkcFMbd1ZVbWnLpwAXAy8ErmkPSdKAjBkGVfVfwGj3/R81wvgCTh1lXyuBlSO0DwGHjFWLJGlq+BfIkiTDQJJkGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEjtRGCRZkuTuJMNJVkx3PZK0O9kpwiDJDODzwLHAIuCEJIumtypJ2n3sFGEAHA4MV9WGqvoZcBmwdJprkqTdxszpLqCZC9zfWd8IvG77QUlOBk5uq08mufs5Pt9+wI+f47ZTybrGx7rGx7rGZ6esK+dMqK5XjNaxs4RBX6rqAuCCie4nyVBVLZ6EkiaVdY2PdY2PdY3P7lbXznKaaBNwYGd9XmuTJA3AzhIGNwELkyxIMgtYBqye5pokabexU5wmqqqtSU4DrgVmACurav0UPuWETzVNEesaH+saH+san92qrlTVVOxXkrQL2VlOE0mSppFhIEl6/oZBkn2TrElyT/s5e5RxTye5tT1Wd9oXJFnXvh7j8nZheyB1JXlNkv9Osj7JbUn+sNN3cZL7OjW/ZoL17PBrQJLs0V7/cJuP+Z2+01v73UmOmUgd46zpY0nubHNzXZJXdPpGPJ4DrO19STZ3avjTTt/ydtzvSbJ8wHWd26np+0ke6/RNyZwlWZnk4SR3jNKfJOe1mm9Lclinbyrnaqy63tPquT3Jt5O8utP3g9Z+a5KhAdf1liSPd47V33T6Jv51PlX1vHwAfwesaMsrgHNGGffkKO1XAMva8heBDw2qLuC3gIVt+eXAA8A+bf1i4J2TVMsM4F7gIGAW8F1g0XZjTgG+2JaXAZe35UVt/B7AgrafGQOq6a3Ai9ryh7bVtKPjOcD5eh/wuRG23RfY0H7ObsuzB1XXduM/TO8mjSmdM+DNwGHAHaP0HwdcAwQ4Alg31XPVZ11v2PZ89L4iZ12n7wfAftM0X28BvjHR4z/a43n7yYDe11lc0pYvAY7vd8MkAY4EVj2X7SdaV1V9v6ruacv/AzwMzJmk5+/q52tAuvWuAo5q87MUuKyqnqqq+4Dhtr8pr6mqbqiqn7TVtfT+LmUQJvK1KccAa6pqS1U9CqwBlkxTXScAX52k5x5VVf0nsGUHQ5YCl1bPWmCfJAcwtXM1Zl1V9e32vDDA368+5ms0k/J1Ps/nMNi/qh5oyw8C+48ybs8kQ0nWJjm+tb0UeKyqtrb1jfS+MmOQdQGQ5HB6aX9vp/ns9jH23CR7TKCWkb4GZPvX+csxbT4epzc//Ww7VTV1nUTv3eU2Ix3PydJvbX/Qjs+qJNv+mHKq5mtc+26n1BYA13eap3LOdmS0uqdyrsZr+9+vAv4jyc3pfT3OoL0+yXeTXJPk4NY2KfO1U/ydwXOV5JvAy0boOqO7UlWVZLR7aF9RVZuSHARcn+R2ev/gTXddtHdJXwaWV9UvWvPp9EJkFr37jT8OnDWRendVSd4LLAZ+t9P8rONZVfeOvIcp8W/AV6vqqSR/Ru9T1ZEDfP6xLANWVdXTnbbpnrOdUpK30guDN3Wa39Tm6jeANUm+197RD8J36B2rJ5McB/wrsHCydr5LfzKoqrdV1SEjPK4EHmr/mG77R/XhUfaxqf3cAHwLOBR4hN5H1m1hOa6vx5iMupLsBVwFnNE+Qm/b9wPtY/VTwJeY2KmZfr4G5Jdj2nzsTW9+puorRPrab5K30QvXd7S5AEY9npNlzNqq6pFOPRcCr+1326msq2MZ250imuI525HR6p72r6dJ8jv0jt/SqnpkW3tnrh4G/oXJOTXal6p6oqqebMtXAy9Ish+TNV/P9WLHzv4A/p5nXqj9uxHGzAb2aMv7AffQLrwAX+OZF5BPGWBds4DrgI+O0HdA+xngM8CnJ1DLTHoX5xbwqwtPB2835lSeeQH5irZ8MM+8gLyBybmA3E9Nh9I7bbaw3+M5Sceun9oO6Cz/PrC2Le8L3NdqnN2W9x1UXW3cq+hdAM0A52w+o18QfTvPvIB841TPVZ91/Sa9a2Bv2K79xcCvd5a/DSwZYF0v23bs6IXQj9rc9XX8x3zuyXwhO9OD3nnt69ov9ze3/TLRO61wYVt+A3B7m7zbgZM62x8E3Nh+Kb627T+YAdX1XuDnwK2dx2ta3/Wt1juAfwJeMsF6jgO+T+8f1zNa21n03nED7Nle/3Cbj4M6257RtrsbOHYSj91YNX0TeKgzN6vHOp4DrO1vgfWthhuAV3W2/ZM2j8PA+wdZV1v/BNu9eZjKOaP3CeSB9ru8kd4plw8CH2z9ofc/tbq3PffiAc3VWHVdCDza+f0aau0HtXn6bjvGZwy4rtM6v1tr6YTVSMd/vA+/jkKStGtfM5AkTQ7DQJJkGEiSDANJEoaBJAnDQJKEYSBJAv4fB7MeXQLmSK8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(Y_train, bins=range(0,3), align='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7073,
     "status": "ok",
     "timestamp": 1599324175154,
     "user": {
      "displayName": "Chris Greening",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhzkETr7y27ciZfW4lregDo2YPFRrA30ouOuL6TIQ=s64",
      "userId": "14199137355227635747"
     },
     "user_tz": -60
    },
    "id": "-60v8-m3OgOF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 22:30:21.451796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31009 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:8a:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "# create the datasets for training\n",
    "batch_size = 30\n",
    "\n",
    "train_dataset = Dataset.from_tensor_slices(\n",
    "    (X_train, Y_train)\n",
    ").repeat(\n",
    "    count=-1\n",
    ").shuffle(\n",
    "    len(X_train)\n",
    ").batch(\n",
    "    batch_size\n",
    ")\n",
    "\n",
    "validation_dataset = Dataset.from_tensor_slices((X_validate, Y_validate)).batch(X_validate.shape[0])\n",
    "\n",
    "test_dataset = Dataset.from_tensor_slices((X_test, Y_test)).batch(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 593
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1497,
     "status": "ok",
     "timestamp": 1599324179335,
     "user": {
      "displayName": "Chris Greening",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhzkETr7y27ciZfW4lregDo2YPFRrA30ouOuL6TIQ=s64",
      "userId": "14199137355227635747"
     },
     "user_tz": -60
    },
    "id": "Wbnijb64OgOM",
    "outputId": "29e1706e-28e1-407d-b9dd-4f0839af6246"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_layer1 (Conv2D)         (None, 149, 43, 4)        40        \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 149, 172)          0         \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 32)                19776     \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 20,905\n",
      "Trainable params: 20,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model = Sequential([\n",
    "#     Conv2D(4, 3, \n",
    "#            padding='same',\n",
    "#            activation='relu',\n",
    "#            kernel_regularizer=regularizers.l2(0.001),\n",
    "#            name='conv_layer1',\n",
    "#            input_shape=(IMG_WIDTH, IMG_HEIGHT, 1)),\n",
    "#     MaxPooling2D(name='max_pooling1', pool_size=(2,2)),\n",
    "#     Conv2D(4, 3, \n",
    "#            padding='same',\n",
    "#            activation='relu',\n",
    "#            kernel_regularizer=regularizers.l2(0.001),\n",
    "#            name='conv_layer2'),\n",
    "#     MaxPooling2D(name='max_pooling2', pool_size=(2,2)),\n",
    "#     Flatten(),\n",
    "#     Dropout(0.2),\n",
    "#     Dense(\n",
    "#         40,\n",
    "#         activation='relu',\n",
    "#         kernel_regularizer=regularizers.l2(0.001),\n",
    "#         name='hidden_layer1'\n",
    "#     ),\n",
    "#     Dense(\n",
    "#         1, \n",
    "#         activation='sigmoid',\n",
    "#         kernel_regularizer=regularizers.l2(0.001),\n",
    "#         name='output'\n",
    "#     )\n",
    "# ])\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(4, 3, \n",
    "           padding='same',\n",
    "           activation='relu',\n",
    "           kernel_regularizer=regularizers.l2(0.001),\n",
    "           name='conv_layer1',\n",
    "           input_shape=(IMG_WIDTH, IMG_HEIGHT, 1)),\n",
    "#     MaxPooling2D(name='max_pooling1', pool_size=(2,2)),\n",
    "    tf.keras.layers.Reshape((IMG_WIDTH, 43*4)),\n",
    "    tf.keras.layers.GRU(32, dropout=0.3),\n",
    "    Dense(\n",
    "        32,\n",
    "        activation='relu',\n",
    "        kernel_regularizer=regularizers.l2(0.001),\n",
    "        name='hidden_layer1'\n",
    "    ),\n",
    "#     Dropout(0.2),\n",
    "#     Dense(\n",
    "#         32,\n",
    "#         activation='relu',\n",
    "#         kernel_regularizer=regularizers.l2(0.001),\n",
    "#         name='hidden_layer2'\n",
    "#     ),\n",
    "    Dense(\n",
    "        1, \n",
    "        activation='sigmoid',\n",
    "        kernel_regularizer=regularizers.l2(0.001),\n",
    "        name='output'\n",
    "    )\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 970,
     "status": "ok",
     "timestamp": 1599324186691,
     "user": {
      "displayName": "Chris Greening",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhzkETr7y27ciZfW4lregDo2YPFRrA30ouOuL6TIQ=s64",
      "userId": "14199137355227635747"
     },
     "user_tz": -60
    },
    "id": "gnEC2AOdOgOO"
   },
   "outputs": [],
   "source": [
    "epochs=30\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pUzYHZJ2OgOR"
   },
   "source": [
    "# Logging to tensorboard\n",
    "We log the training stats along with the confusion matrix of the test data - should we be using the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1008,
     "status": "ok",
     "timestamp": 1599324189567,
     "user": {
      "displayName": "Chris Greening",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhzkETr7y27ciZfW4lregDo2YPFRrA30ouOuL6TIQ=s64",
      "userId": "14199137355227635747"
     },
     "user_tz": -60
    },
    "id": "cwBFfW6TOgOR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 22:30:33.401372: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2023-04-23 22:30:33.401430: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2023-04-23 22:30:33.401513: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1614] Profiler found 1 GPUs\n",
      "2023-04-23 22:30:33.881942: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2023-04-23 22:30:33.882216: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1749] CUPTI activity buffer flushed\n"
     ]
    }
   ],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "me2W-gteOgOT"
   },
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 829
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 233329,
     "status": "ok",
     "timestamp": 1599324428053,
     "user": {
      "displayName": "Chris Greening",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhzkETr7y27ciZfW4lregDo2YPFRrA30ouOuL6TIQ=s64",
      "userId": "14199137355227635747"
     },
     "user_tz": -60
    },
    "id": "9s--XYYIOgOW",
    "outputId": "d623eb95-df61-4e2c-9acd-a82e19aaf5e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 22:30:39.427120: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-04-23 22:30:43.384765: I tensorflow/stream_executor/cuda/cuda_dnn.cc:381] Loaded cuDNN version 8204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1/4282 [..............................] - ETA: 9:29:58 - loss: 0.5956 - accuracy: 0.7667"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 22:30:46.010434: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2023-04-23 22:30:46.010498: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   3/4282 [..............................] - ETA: 43:26 - loss: 0.6879 - accuracy: 0.6778  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 22:30:47.008664: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2023-04-23 22:30:47.009014: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1749] CUPTI activity buffer flushed\n",
      "2023-04-23 22:30:47.070160: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 909 callback api events and 888 activity events. \n",
      "2023-04-23 22:30:47.091942: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2023-04-23 22:30:47.112335: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/fit/20230423-223033/train/plugins/profile/2023_04_23_22_30_47\n",
      "\n",
      "2023-04-23 22:30:47.124394: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to logs/fit/20230423-223033/train/plugins/profile/2023_04_23_22_30_47/jarvis-vcjob-bbac89a1727cd5dd9c6b64cf16f35d19-master-0.trace.json.gz\n",
      "2023-04-23 22:30:47.142596: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/fit/20230423-223033/train/plugins/profile/2023_04_23_22_30_47\n",
      "\n",
      "2023-04-23 22:30:47.144330: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to logs/fit/20230423-223033/train/plugins/profile/2023_04_23_22_30_47/jarvis-vcjob-bbac89a1727cd5dd9c6b64cf16f35d19-master-0.memory_profile.json.gz\n",
      "2023-04-23 22:30:47.145185: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/fit/20230423-223033/train/plugins/profile/2023_04_23_22_30_47\n",
      "Dumped tool data for xplane.pb to logs/fit/20230423-223033/train/plugins/profile/2023_04_23_22_30_47/jarvis-vcjob-bbac89a1727cd5dd9c6b64cf16f35d19-master-0.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/fit/20230423-223033/train/plugins/profile/2023_04_23_22_30_47/jarvis-vcjob-bbac89a1727cd5dd9c6b64cf16f35d19-master-0.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/fit/20230423-223033/train/plugins/profile/2023_04_23_22_30_47/jarvis-vcjob-bbac89a1727cd5dd9c6b64cf16f35d19-master-0.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/fit/20230423-223033/train/plugins/profile/2023_04_23_22_30_47/jarvis-vcjob-bbac89a1727cd5dd9c6b64cf16f35d19-master-0.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/fit/20230423-223033/train/plugins/profile/2023_04_23_22_30_47/jarvis-vcjob-bbac89a1727cd5dd9c6b64cf16f35d19-master-0.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4282/4282 [==============================] - 55s 11ms/step - loss: 0.1261 - accuracy: 0.9560 - val_loss: 0.1105 - val_accuracy: 0.9729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 22:31:34.873395: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoint-v2.model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoint-v2.model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "4282/4282 [==============================] - 42s 10ms/step - loss: 0.0328 - accuracy: 0.9918 - val_loss: 0.1227 - val_accuracy: 0.9714\n",
      "Epoch 3/30\n",
      "4282/4282 [==============================] - 40s 9ms/step - loss: 0.0252 - accuracy: 0.9942 - val_loss: 0.1409 - val_accuracy: 0.9722\n",
      "Epoch 4/30\n",
      "4282/4282 [==============================] - 39s 9ms/step - loss: 0.0195 - accuracy: 0.9961 - val_loss: 0.0997 - val_accuracy: 0.9756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoint-v2.model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoint-v2.model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "4282/4282 [==============================] - 40s 9ms/step - loss: 0.0174 - accuracy: 0.9968 - val_loss: 0.1388 - val_accuracy: 0.9749\n",
      "Epoch 6/30\n",
      "4282/4282 [==============================] - 39s 9ms/step - loss: 0.0159 - accuracy: 0.9969 - val_loss: 0.1548 - val_accuracy: 0.9718\n",
      "Epoch 7/30\n",
      "4282/4282 [==============================] - 37s 9ms/step - loss: 0.0161 - accuracy: 0.9970 - val_loss: 0.1207 - val_accuracy: 0.9728\n",
      "Epoch 8/30\n",
      "4282/4282 [==============================] - 37s 9ms/step - loss: 0.0138 - accuracy: 0.9977 - val_loss: 0.1308 - val_accuracy: 0.9725\n",
      "Epoch 9/30\n",
      "4282/4282 [==============================] - 38s 9ms/step - loss: 0.0139 - accuracy: 0.9975 - val_loss: 0.1298 - val_accuracy: 0.9707\n",
      "Epoch 10/30\n",
      "4282/4282 [==============================] - 38s 9ms/step - loss: 0.0123 - accuracy: 0.9979 - val_loss: 0.1819 - val_accuracy: 0.9709\n",
      "Epoch 11/30\n",
      "4282/4282 [==============================] - 37s 9ms/step - loss: 0.0118 - accuracy: 0.9981 - val_loss: 0.1746 - val_accuracy: 0.9694\n",
      "Epoch 12/30\n",
      "4282/4282 [==============================] - 37s 9ms/step - loss: 0.0109 - accuracy: 0.9982 - val_loss: 0.1876 - val_accuracy: 0.9696\n",
      "Epoch 13/30\n",
      "4282/4282 [==============================] - 37s 9ms/step - loss: 0.0116 - accuracy: 0.9980 - val_loss: 0.1462 - val_accuracy: 0.9765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoint-v2.model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoint-v2.model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n",
      "4282/4282 [==============================] - 37s 9ms/step - loss: 0.0114 - accuracy: 0.9981 - val_loss: 0.1704 - val_accuracy: 0.9670\n",
      "Epoch 15/30\n",
      "4282/4282 [==============================] - 38s 9ms/step - loss: 0.0102 - accuracy: 0.9985 - val_loss: 0.1434 - val_accuracy: 0.9758\n",
      "Epoch 16/30\n",
      "4282/4282 [==============================] - 37s 9ms/step - loss: 0.0100 - accuracy: 0.9985 - val_loss: 0.1648 - val_accuracy: 0.9734\n",
      "Epoch 17/30\n",
      "4282/4282 [==============================] - 38s 9ms/step - loss: 0.0099 - accuracy: 0.9985 - val_loss: 0.1615 - val_accuracy: 0.9756\n",
      "Epoch 18/30\n",
      "4282/4282 [==============================] - 37s 9ms/step - loss: 0.0098 - accuracy: 0.9987 - val_loss: 0.1713 - val_accuracy: 0.9732\n",
      "Epoch 19/30\n",
      "4282/4282 [==============================] - 39s 9ms/step - loss: 0.0098 - accuracy: 0.9986 - val_loss: 0.1448 - val_accuracy: 0.9760\n",
      "Epoch 20/30\n",
      "4282/4282 [==============================] - 39s 9ms/step - loss: 0.0087 - accuracy: 0.9990 - val_loss: 0.1434 - val_accuracy: 0.9775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoint-v2.model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoint-v2.model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "4282/4282 [==============================] - 39s 9ms/step - loss: 0.0096 - accuracy: 0.9986 - val_loss: 0.1445 - val_accuracy: 0.9749\n",
      "Epoch 22/30\n",
      "4282/4282 [==============================] - 37s 9ms/step - loss: 0.0094 - accuracy: 0.9986 - val_loss: 0.1627 - val_accuracy: 0.9756\n",
      "Epoch 23/30\n",
      "4282/4282 [==============================] - 38s 9ms/step - loss: 0.0086 - accuracy: 0.9989 - val_loss: 0.1685 - val_accuracy: 0.9707\n",
      "Epoch 24/30\n",
      "4282/4282 [==============================] - 37s 9ms/step - loss: 0.0089 - accuracy: 0.9989 - val_loss: 0.1909 - val_accuracy: 0.9670\n",
      "Epoch 25/30\n",
      "4282/4282 [==============================] - 38s 9ms/step - loss: 0.0082 - accuracy: 0.9990 - val_loss: 0.1391 - val_accuracy: 0.9765\n",
      "Epoch 26/30\n",
      "4282/4282 [==============================] - 36s 8ms/step - loss: 0.0086 - accuracy: 0.9989 - val_loss: 0.1222 - val_accuracy: 0.9732\n",
      "Epoch 27/30\n",
      "4282/4282 [==============================] - 37s 9ms/step - loss: 0.0086 - accuracy: 0.9989 - val_loss: 0.1488 - val_accuracy: 0.9762\n",
      "Epoch 28/30\n",
      "4282/4282 [==============================] - 38s 9ms/step - loss: 0.0086 - accuracy: 0.9990 - val_loss: 0.1288 - val_accuracy: 0.9760\n",
      "Epoch 29/30\n",
      "4282/4282 [==============================] - 38s 9ms/step - loss: 0.0084 - accuracy: 0.9989 - val_loss: 0.1292 - val_accuracy: 0.9770\n",
      "Epoch 30/30\n",
      "4282/4282 [==============================] - 38s 9ms/step - loss: 0.0083 - accuracy: 0.9990 - val_loss: 0.1383 - val_accuracy: 0.9750\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"checkpoint-v2.model\",\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=len(X_train) // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_dataset,\n",
    "    validation_steps=1,\n",
    "    callbacks=[tensorboard_callback, model_checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 233637,
     "status": "ok",
     "timestamp": 1599324431300,
     "user": {
      "displayName": "Chris Greening",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhzkETr7y27ciZfW4lregDo2YPFRrA30ouOuL6TIQ=s64",
      "userId": "14199137355227635747"
     },
     "user_tz": -60
    },
    "id": "v1u5dvHuYpsg",
    "outputId": "90a474da-39d1-49a8-8887-ab725af57795"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trained-v2.model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trained-v2.model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"trained-v2.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s8Vok4uqFv6_"
   },
   "source": [
    "# Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1007,
     "status": "error",
     "timestamp": 1599330905822,
     "user": {
      "displayName": "Chris Greening",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhzkETr7y27ciZfW4lregDo2YPFRrA30ouOuL6TIQ=s64",
      "userId": "14199137355227635747"
     },
     "user_tz": -60
    },
    "id": "21m-pPzgFmhD",
    "outputId": "e9cd084b-9eb9-4818-bf49-4c61f7c55d7f"
   },
   "outputs": [],
   "source": [
    "model2 =  keras.models.load_model(\"checkpoint-v2.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1876,
     "status": "ok",
     "timestamp": 1599310165183,
     "user": {
      "displayName": "Chris Greening",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhzkETr7y27ciZfW4lregDo2YPFRrA30ouOuL6TIQ=s64",
      "userId": "14199137355227635747"
     },
     "user_tz": -60
    },
    "id": "74brwGyVGZ7B",
    "outputId": "042177d6-4a6b-4873-84dd-a26e3925d337"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 1s 4ms/step - loss: 0.1149 - accuracy: 0.9725\n"
     ]
    }
   ],
   "source": [
    "results = model2.evaluate(X_test, tf.cast(Y_test, tf.float32), batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 838,
     "status": "ok",
     "timestamp": 1599308975138,
     "user": {
      "displayName": "Chris Greening",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhzkETr7y27ciZfW4lregDo2YPFRrA30ouOuL6TIQ=s64",
      "userId": "14199137355227635747"
     },
     "user_tz": -60
    },
    "id": "uRkkvWOKM6hv",
    "outputId": "41cee6e7-05b2-4b22-e377-e5748e2fc216"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[ 5068,    21],\n",
       "       [  423, 10637]], dtype=int32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model2.predict_on_batch(X_test)\n",
    "decision = [1 if p > 0.5 else 0 for p in predictions]\n",
    "tf.math.confusion_matrix(Y_test, decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[ 5075,    14],\n",
       "       [  522, 10538]], dtype=int32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model2.predict_on_batch(X_test)\n",
    "decision = [1 if p > 0.9 else 0 for p in predictions]\n",
    "tf.math.confusion_matrix(Y_test, decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 511,
     "status": "error",
     "timestamp": 1599234663798,
     "user": {
      "displayName": "Chris Greening",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhzkETr7y27ciZfW4lregDo2YPFRrA30ouOuL6TIQ=s64",
      "userId": "14199137355227635747"
     },
     "user_tz": -60
    },
    "id": "fZItwJx7yWpY",
    "outputId": "9988d1a0-bc7b-469a-9c2c-d6ec3750512c"
   },
   "outputs": [],
   "source": [
    "complete_train_X = np.concatenate((X_train, X_validate, X_test))\n",
    "complete_train_Y = np.concatenate((Y_train, Y_validate, Y_test))\n",
    "\n",
    "complete_train_dataset = Dataset.from_tensor_slices((complete_train_X, complete_train_Y)).repeat(count=-1).shuffle(300000).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5354/5354 [==============================] - 64s 10ms/step - loss: 0.0123 - accuracy: 0.9976\n",
      "Epoch 2/5\n",
      "5354/5354 [==============================] - 55s 10ms/step - loss: 0.0102 - accuracy: 0.9984\n",
      "Epoch 3/5\n",
      "5354/5354 [==============================] - 54s 10ms/step - loss: 0.0102 - accuracy: 0.9984\n",
      "Epoch 4/5\n",
      "5354/5354 [==============================] - 51s 10ms/step - loss: 0.0095 - accuracy: 0.9987\n",
      "Epoch 5/5\n",
      "5354/5354 [==============================] - 49s 9ms/step - loss: 0.0093 - accuracy: 0.9986\n"
     ]
    }
   ],
   "source": [
    "history = model2.fit(\n",
    "    complete_train_dataset,\n",
    "    steps_per_epoch=len(complete_train_X) // batch_size,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.callbacks.History object at 0x7f739c180df0>\n"
     ]
    }
   ],
   "source": [
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = model2.predict_on_batch(complete_train_X)\n",
    "# decision = [1 if p > 0.5 else 0 for p in predictions]\n",
    "# tf.math.confusion_matrix(complete_train_Y, decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision = [1 if p > 0.95 else 0 for p in predictions]\n",
    "# tf.math.confusion_matrix(complete_train_Y, decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2.save(\"fully_trained.model\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "image_based_training.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
